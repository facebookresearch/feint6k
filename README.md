# Feint6K

**Feint6K** dataset for video-text understanding, from the following paper:

[Rethinking Video-Text Understanding: Retrieval from Counterfactually Augmented Data](#). ECCV 2024.\
[Wufei Ma](https://wufeim.github.io), [Kai Li](https://sites.google.com/view/kaisqu/), [Zhongshi Jiang](https://scholar.google.com/citations?user=h8bGMF4AAAAJ&hl=en), [Moustafa Meshry](http://www.cs.umd.edu/~mmeshry/), [Qihao Liu](https://qihao067.github.io), [Huiyu Wang](https://csrhddlam.github.io), [Christian HÃ¤ne](https://scholar.google.com/citations?user=AliuYd0AAAAJ&hl=en), [Alan Yuille](https://www.cs.jhu.edu/~ayuille/)\
Meta Reality Labs, Johns Hopkins University, Meta AI\
[[`Project Page`]](https://feint6k.github.io) [[`arXiv (coming soon ...)`]](#)

---

We propose a novel evaluation task for video-text understanding, namely *retrieval from counterfactually augmented data* (RCAD), and a new *Feint6K* dataset, to better assess the capabilities of current video-text models and understand their limitations. To succeed on our new task, models must derive a comprehensive understanding of the video from cross-frame reasoning.

<p align="center">
<img src="https://github.com/user-attachments/assets/f0a3e762-f2e2-48fe-9c80-46fc998d625a" width=100% height=100% class="center">
</p>


## Citation

If you find this dataset helpful, please consider citing:

```
@inproceedings{ma2024rethinking,
  title={Rethinking Video-Text Understanding: Retrieval from Counterfactually Augmented Data},
  author={Ma, Wufei and Li, Kai and Jiang, Zhongshi and Meshry, Moustafa and Liu, Qihao and Wang, Huiyu and H{\"a}ne, Christian and Yuille, Alan},
  booktitle={European Conference on Computer Vision},
  year={2024},
  organization={Springer}
}
```
